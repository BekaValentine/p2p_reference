@title  Peer-to-peer Basics
@date   2023-08-10
@author beka

# Peer-to-peer Basics

This document is an attempt to provide a ground-up introduce to peer-to-peer (p2p) technology for people who are familiar with computery things broadly speaking, but not necessarily familiar with p2p. For people familiar with p2p, this will hopefully be a nice, concise picture of the high-level issues.

## What does "peer-to-peer" mean?

"Peer-to-peer" is a term referring to a broad class of technologies for building networked computer systems where all of the participants in the network are more or less equivalent in terms of what they're able to do. This is in contrast to centralized systems that involve significant asymmetries in the roles played by the different participants.

A useful comparison can be made in the problem domain of search. A standard approach to search, from the earliest web search engines through to today's dominant search giants, is to have a service provided by a single entity, such as Google today, or Altavista in the 90s, which people can use to search for information on the web. All of the work is done by the service's computers, and all of the data is stored there as well. The user who wishes to search for something merely visits the search engine and requests some information.

Contrast this with the phenomenon of `#lazyweb` in the later Twitter era. Rather than requesting information from one centralized data warehouse, users of Twitter, and other social media sites, post a request to their social media feed asking their followers if anyone knows anything about the desired subject. If so, people reply with that information. The information is not stored in a single centralized repository, nor is it retrieved by that repository's computers, but rather it's stored in the user's *fellow users*, i.e. their peers, and retrieved from memory by those peers. And moreover, those peers can do the exact same thing and get information from anyone who follows them. Each person can both request information and provide it, so there's symmetry.

Now, there are certainly a lot of confounding factors here, because Twitter and most other social media systems are themselves centralized, but those aren't essential to the point, which is that every relevant participant can play the same roles: everyone can request information and also everyone can provide information. In a sense, then, `#lazyweb` is a form of peer-to-peer search.

Typically, tho, when we talk about p2p stuff, we generally mean not person-to-person, per se, but rather some equivalent thing done by computers. Certainly there are ways in which people do "p2p" research about purely social phenomena that don't involve computers and that's p2p very broadly construed, but usually we mean computery things.

We also often have many different kinds of p2p systems, especially historically, which have more or less p2p-ness. For instance, one of the most famous and historically impactful p2p systems was Napster, a p2p file sharing system. But Napster was not, actually, a p2p search system. It's search was entirely centralized on Napster's servers, which is what lead to its eventual death at the hands of the Recording Industry Association of America (RIAA)'s copyright lawyers. What made Napster p2p was that the music and other files being shared on the system were all distributed around on the computers of the users, and they were transfered directly from one user to another, without going through Napster's computers at all. Napster merely acted as a kind of directory for where to find the files in question. A similar structure exists today in the world of BitTorrent, arguably the most successful p2p tool ever made. BitTorrent doesn't have a single search mechanism like Napster did, rather, it has an entire ecosystem of search websites, but they are themselves centrally controlled by the site operators, and have similar problems with lawsuits. The most famous of the torrent search websites -- The Pirate Bay -- has only managed to avoid permadeath by being located in Sweden, which gives them certain legal protections (at least until the RIAA and MPAA manage to get Swedish law changed).

But there are many many kinds of p2p systems that are different than this. A lot of research over the last 25 or 30 years has gone into finding ways to store, index, and retrieve information in decentralized, peer-to-peer ways. Lots of points of variation exist around how much centralization, and what kind, is or is not needed, and how it can be avoided. Many of the techniques have similar shapes, and so we can give a fairly high level overview of many many p2p systems look like, if you squint and ignore the details. In the following sections, we'll look at a few high-level topics, and some variations and issues within them. The plan is as follows:

1. How peers find one another: bootstrapping and network topologies
2. What kind of stuff is out there: things, metadata about things, and capabilities
3. How stuff is found: locating particular things and discovering things that satisfy criteria

So, let's proceed!

## How Peers Find One Another

A p2p network is first a foremost a mechanism for people and computers to communicate with one another. That requires that they can in fact make contact, and that assuming they can do that, that they know *how* to contact one another. The first problem, that of establishing contact with the p2p network as a whole, is called bootstrapping, and the second, knowing how to communicate with particular other peers, is called routing.

### Bootstrapping

Bootstrapping is generally a pretty simple problem to solve. If we assume that whenever two peers are "connected" to the network, there is some way for them to communicate, then to connect to the network simply requires that a new peer knows at least one old peer and can communicate with them. From that, the peer can then connect through to other peers (or possibly learn about other peers to talk to them more directly). 

However, it's not always a good idea to use this bootstrap-via-anyone approach. For one thing, p2p networks can split and fragment (a phenomenon called a "netsplit", especially wrt IRC), and that kind of scheme can possibly exacerbate the problem. One very common way of bootstrapping is instead to have a handful of "bootstrap nodes", which are computers (sometimes peers, sometimes not) who's sole purpose is to act as a way to get introduced to peers on the network. Bootstrap nodes do have some downsides, of course. They have to be fairly widely accessible and have a stable location, which tends to entail something like a permanent IP address or domain name, and a variety of more advanced sysadmin-type skills are therefore required to run them. Bootstrap nodes in general are a kind of centralization point, which is why some p2p systems avoid them. On the other hand, their role is so minimal that when they become problematic, it's not hard to swap them out. Also, typically bootstrap nodes tend to be non-unique, and so concentrations of power are harder to achieve because bootstrapping can be done with entirely non-overlapping admin crews. Taking over one bootstrap node has no effect on the others and doesn't prevent people from connecting to the network, so urgency of removing the now-problematic bootstrap node is minimal. Additionally, the worst that a malicious bootstrap node can do is create a netsplit because their only role is to connect peers, but even that is hard to achieve if new peers always rely on multiple bootstrap nodes. The non-malicious bootstrap nodes would still be able to connect people across the split, and so you'd need highly coordinated attacks for bootstrap nodes to become a true problem for a p2p system.

Not all systems have a bootstrapping process in any real sense, however. For instance, Napster's p2p architecture really didn't need to bootstrap anything. Communicate in Napster was direct from one peer to another via direct TCP/IP connections, and they found each other first logging with Napster's servers what files they themselves had available, and then by searching the servers for locations of files. Napster therefore acted more as a central index or address book, and not really like a bootstrap node.

### Overview of Routing and Topologies

Once a peer is *on* the network, it has to be able to talk to particular people. There are many ways this can happen. The simplest way is to just use IP addresses directly as the means of identifying other peers, but that often means that for any application where peer identity needs to persist, there are problems due to dynamic IP assignment. Instead, it's often convenient to separate an enduring peer identity from a potentially ephemeral network address. This also has the benefit of making network into a substrate independent system that can work both on an IP network but also on, say, a sneakernet or a traditional postal system.

Peer IDs are generally numbers, or equivalent to numbers, and ought to be unique, so no two peers have the same ID. In principle, we could guarantee this by having a single computer do this (perhaps a bootstrap node) but that could produce problems for concentrations of power, so th more common approach is to have each peer generate a random number. Since that by itself wouldn't prevent duplicate IDs, especially in the case of malicious peers, a very common random number generation approach is to require that the number be the public key portion of a public-private key pair. Then, anyone can "copy" the public key of another peer, but they wouldn't have the corresponding private key and so wouldn't be accepted as being identified by the public key. Only the peer with the corresponding private key would be accepted as identified by the public key. And of course this can be verified with standard cryptographi techniques like signing challenges. In such settings we typically find that the identity can usefully be taken to be the *hash* of the public key, not the public key directly. This enforces a fixed size for the peer ID, since some public key schemas can have different key lengths. This does mean there as a slightly higher chance of identity collisions, but it's usually so unlikely as to be irrelevant.

So then, once we have peer IDs, we still need to know how peers talk to each other. If you had a giant address book, called a "routing table", of all of the peer IDs and the current IP addresses for each of those peers, it'd be trivial, you'd just look up the peer's current IP address and send a message. But that would require every peer to know about every other peer, which is a bit of a burden. For instance, BitTorrent has over 170 *million* active monthly users, so assuming that a peer ID is a SHA-256 hash, thats 256 bits/32 bytes, and an IPv4 address is 4 bytes, so at a minimum that's 36 bytes per peer, or on the order of 6 *gigabytes* of address information. It's completely unreasonable to expect people to download 6 gigs of network metadata on connection to the network before they can even use the network. It's also inconceivable how you'd keep all of that information accurate and up to date as people come and go on the network. So usually we don't.

Instead, p2p systems define some kind of routing mechanism over a virtual network topology. In physical networks, the topology is defined by the literal cables connecting devices together. In a p2p network, the topology is defined logical, defined usually by mathematical constructs, forming what's called an "overlay network" on top of the underlying substract network. As mentioned wrt peer IDs, this separation has the benefit of making the overlay network substrate independent and capable of bridging different substrates entirely.

Abstractly, then, what a p2p system does is define some mechanism by which peer IDs can be related to one another to form some kind of structure, often best seen as some form of graph that represents what other peers any given peer has to have in their metaphorical address book/routing table. As long as the mathematical structure or graph, whatever it actually is, guarantees that there is *some* path through th structure between each two peers, then everything works fine and any pair of peers can talk as needed, despite not having a routing table entry for every peer in the network. The choice of what this abstract mathematical structure or graph is depends greatly on the tasks that the p2p system is intended to solve. It's possible in principle to use a structure that is entirely disconnected from the purpose of the network, but tighter integration can lead to less network traffic for communication, and so it's quite common to couple the structures. We'll look at this in more depth later, when we talk about what is actually out there on the p2p network.

### Topologies and Distance Metrics

How the topology of the overlay network is defined is in principle arbitrary. One could imagine having the topology be just some structure chosen by a coordinating actor, some random tree or graph or whatever, that is then partially shared with each peer. This is actually not uncommon in distributed sytems for things like cloud computing, where the network of computers might act in a non-centralized fashion among themselves when handling tasks like database lookups, but who's architecture is completely controlled by some organization like Google Cloud. But in a p2p stting where we tend to eschew centralizd control, we also tend to avoid having coordinating actors. Not always, but it's generally the case that p2p networks prefer to have topologies defined by a mathematical principle.

A very common way to do this is to have some kind of "distance metric", that is to say, a way of computing a notion of "distance" between any two peers, or rather, their respective peer IDs. Possibly the simplest distance metric is to just treat each peer ID as a number, and use absolutely values of numerical subtraction. Then, for instance, one can imagine requiring each peer to know the peer that is closest above and below them. This would form a linear topology. Let's look at an example of such a network to see how this would work.

Let's simplify and say that peer IDs are just 4 bits long, so there's at most 16 distinct peer IDs. Suppose that there are in fact only 5 peers on the network, however, and their peer IDs are the 4-bit bitstrings corresponding to the numbers 2, 5, 8, and 13. Then, each peer has to know the closest peer below and above: peer 2 knows about peer 5, 5 knows about 2 and 8, 8 knows about 5 and 13, and 13 knows about 8. That is to say, they know the IP addresses of those neighboring peers. Then it's possible for any peer, say 2, to be said to be connected to any other peer, say, 13, because even tho 2 does not know 13's IP addrss, 2 knows someone (5) who knows someone (8) who knows 13's IP address.

Obviously this particular choice of topology is unpleasant. If there are lots of peers on the network, the number of intermediate peers between any two random peers is going to be high, but also somewhat asymmetric, with peers toward the ends of the line of peer IDs having a lot of intermediate peers compared to peers toward the middle of the line. Few, if any, p2p systems use a linear key space. Gluing the ends of the line together to form a ring is a common idea, however, and Chord uses this, together with a slight difference in how the distance is calculated.

Another common trick to making the topology nicer is to require that peers don't simply know about the *nearest* neighboring peers, but rather to know about peers at various distances away. For instanc, using an exponential backoff of distance, by having a per know about its closest neighbor, (ie 1 peer away), the next closest (2 peers away), the next-next-next closest (4 intermediate peers), and so on (2^n peers away at each step), up to some maximum distance. Because the network now has these links over larger distances, the path to "far away" peers can be quite short.

Many other distance metrics and topologies exist. Kademlia uses the numerical value of the bitwise XOR as the distance, and then makes use of similar backoff-based approach to ensure connectivity. Other systems use topologies determined partially by the sort of problem that the p2p network is used to handle. For instance, spatial information often turns into some kind of tree structure on peers, and if there's a distance metric at all, it's derived from the tree, and in either case what peers know is always in relation to that tree, eg. "child" peers, "parent" peers, "sibling" peers, etc.

It's worth pointing out tho that the concept of a distinct metric and the concept of a network topology are distinct. The distance metric above is a linear space over all possible peer IDs, but the actual network topology might be a linear subset (if peers know their nearest neighbor(s)), or it might be a more complicated graph structure (if peers know exponentially further away peers).

Not all p2p systems use distance metrics and derived topologies, however. Some just have an extremely ephemeral topology defined by things like how peers interact over time, random sharing of information, etc.

### Communicating through the Routing Topology

With routing topologies in mind, we can then ask the question "how do peers actually communicate with one another using such a topology?" In the simplest case, a peer just knows the IP address of the other peer it wants to talk to and so nothing interesting has to happen at all. The topology is only relevant for when peers *don't* know the IP address of the peer they want to communicate with. A very common strategy, possibly the most common, is to rely on the distance metric, when there is one, to select the known peer that is closest to the target peer. Using the linear distance metric and nearest-neighbor topology from earlier, if 5 wants to communicate with 13, but it knows only about 2 and 8, it can find the distance from each of those to 13, which are 11 and 5, respectively. The linear structure of the distance metric and of the associated topology guarantees that if 13 is on the network, it's closer to peer 8 than to peer 2, in terms of intermediate peers, and so 5 can instead communicate with just 8 in some way in order to facilitate its communication with 13.

Just how that intermediated communication works depends on the p2p network's design, but there are broadly speaking three techniques. I don't know if there are standard names for these so I'll call them Delegation, Forwarding, and Redirection.

Delegation is the simplest method, where the originating peer, in the example that would be peer 5, simply gives a message intended for some other peer, here 13, to some delegate peer to handle, here that's peer 8. The delegate peer then is responsible for figuring out what to do with it, and when 8 gets a response, it then passes the response back to 5. So to delegate a message, it's given to a nearer peer and that peer handles the remainder of the problem. This is analogous to having a function call another function, in a kind of recursive divide and conquer way.

Forwarding is very similar to Delegation, in that it involves passing the message to a nearer peer for them to handle, but unlike Delegation, that other peer serves only to forward the message out to the destination, and any response would then be handled entirely separately. Usually the response reaches the originator by direct response from the destination by passing along the originator's IP address along in the message, but alternatively the destination peer and issue its own response messag which will take whatever route results from swapping the roles of originator and destination. This is analogous to a callback or continuation style of programming, or to a message-passing style of object oriented programming.

The final technique, Redirection, is similar to Forwarding, except that instead of sending the *message* to the nearest known peer, the originator asks that peer for a *closer* peer to the destination, and then asks that peer for a closer one, and so on and so on until the destination peer is found, and then finally the message is sent directly, and responses typically are also direct. In this case, the request for a closer peer hands to give the originator the closer peer's IP address. Typically the closer peer's ID is also given, so that the originator can expand their routing table for caching purposes.

In the case where no real interesting topology or distance metric exists, Delegation tends to be far more common, and techniques that involve delegating to *every* known peer (known as "flooding") are common, leading to messages getting sent to every peer in the network. This is often undesirable for many reasons, and so topologies are quite popular.

The choice between these three main techniques is mostly determined by the kind of p2p network that's involved. For instance, if messages or responses are of potentially arbitrary size, it's quite a burden on peers and the network as a whole to send those messsages, so Delegation and Forwarding tend to be avoided, while Redirection is common. But this can depend greatly on the purpose of the network. For instance, Freenet lets users store arbitrary data on other Freenet peers, and requests for data use a Delegation technique. The peers along the request route then cache the data being returned, making it possible for future requests for that data to be potentially much faster by having intermediate peers return cached data instead of continuing to pass the request message toward the destination peer.

## What Kind of Stuff is Out There

So far, we've only talked about how peers communicate with one another, not what they're communicating about. The most common kind of p2p system people know about is a file sharing system, where the purpose of the network is to provide access to files/data. Most, or maybe all, of the real world examples above (BitTorrent, Freenet, Napster) are file sharing in some form. Their purpose is precisely to distribute files and data. Other systems are intended to provide access to other kinds of resources, such as computation. For instance, it's possible to have a network where peers request other peers perform certain computational tasks for them. Spam filtering might be an example of such a task, for instance. Or one can imagine a system where access to manufacturing tools like printers is required, and so the system facilitates routing of documents to be printed to computers connected to printers (how you get the printout is another question entirely!).

But while all of these are fundamentally different sorts of *resources* that are available on the network, typically what is stored *on the network* is actually just data. What that data is can vary. In the printer example it really couldn't be much more than which peers have access to what (kinds of) printers. In some other cases, such as p2p networks for communication between users, nothing is really stored on the network at all, because everything is about shuttling messages around between *people*, so topology is all that really matters.

Generally speaking, tho, what is "out there" on the network is actually just data, if anything. What that data is depends on the network. So let's compare two data-oriented networks, Freenet and BitTorrent. Both of these are means of distributing data -- files and directors and whatever else one things of as data. But they way they do it is quite different. In the Freenet case, when a peer, lets call them Initiator, wants to store data on the network, they *transfer* that data to another peer, lets call them Storer, which is chosen in a semi-random way, who then saves that data to disk. How Storer is chosen is orthogonal, the point is that Storer has the responsibility of now retaining the data and then later supplying it to any random Requestor who comes along. That could be bad news for Storer, if the data is quite large!

BitTorrent, on the other hand, doesn't work that way. When a BitTorrent peer wants some data to be available through BitTorrent, they instead *announce to the network* that they they have the data and any Requestor can come to them to get the data. How do they announce it? By acting as the Initiator for storing some *metadata* (their own peer ID) at Storer. So rather than Storer being responsible for some large file of unknown origin, Storer simply has to maintain a small list of peer IDs for where the file can be found. The file itself is still located on Initiator, and Initiator is responsible for sending it to Requestor. Storer's only job is to maintain the location metadata. This is far less of a burden to Storer.

This is a very big difference in kinds of p2p systems. The tradeoffs depend on goals. Freenet is intended to be censorship resistant, and so they want data itself to be spread around to many places so that it's hard to eliminate from the network. If peers had lots of control over what they store, then censorship could be much easier. BitTorrent, on the other hand, isn't aimed at censorship resistance but rather on high throughput of data, and so making it easy for more capable peers with better networks to just opt in to hosting whatever data they think needs to be available. It also means that part of the BitTorrent protocol can be that if you retrieve some data, you automatically also announce to the world that you can provide it to others, thereby ensuring that the availability and throughput goes up in proportion to the popularity. Freenet, by contrast, handles this by caching, which again is semi-random, and not related to the caching peers' active request for the data but rather by accident of routing messages.

In the case of the compute and printer examples, what would have to be stored on the network would be data about who has what kinds of resources available, making it more akin to the BitTorrent model. There is no analog to the Freenet system possible, short of literally shipping devices around through some external courier service. Perhaps in Star Trek you can beam actual computers between peers, but in the real world, you only beam metadata about where those resources can be. So in some sense, Freenet-like systems are a special case where the resource in question is mere information and so, like the locational metadata, can be transfered.

## How Stuff is Found

Resources existing on the network are no use to anyone if they can't be located. Other peers have to be able to *find* a resource to do something with it! And if they want to add or change or remove a resources, they have to know where it is or should be. So we have to have some way of relating the data (or resource-location metadata) to some peers on the network for storage. An extremely common method, perhaps the *most* common method, when the resource is data itself, as in a file sharing system, is to hash the data itself (NOT the location metadata) using the same hashing function that's used to hash a peer's public key generate the peer ID. This then puts the hash of the data into the same value range as the peer IDs themselves (e.g. 256-bit bitstrings), making them comparable by any distance metric that is defined in the system. It's then typical for the data (or location metadata) to be stored at peers whose IDs are near the hash of the data according to the distance metric, for instance at the 10 closest peers. This is the kind of scheme that Freenet uses, where the data itself is hashed and then stored at the peers whose IDs are near to that hash. IPFS, another file sharing p2p network, also uses the hash of the content in order to select peers, except on IPFS it's the location metadata that's stored at the peers near to the content hash, rather than the content data itself. For BitTorrent, there's one greater layer of indirection: the torrent file. Rather than hashing the content itself, a metadata file called a torrent file wraps up a bunch of information (including the hash of the data) and then the hash of *that* file is whats used to select peers who will store the location information. But, as with IPFS, the location information is who has the actual content, not who has the torrent file. There are other techniques too, of course. These are all just about how to locate specific pieces of data and files. We could also imagine locating particular non-data resources this way as well. For instance, if somehow every printer on the network were given a unique ID, which is not uncommon in universities or corporate settings, then you could hash that ID and then store metadata about the printer at the peers nearest to that hash. Search for information in this setting requires that we know the hash of the thing we want to access (as in Freenet or IPFS), or the hash of some metadata file we can hash (as in BitTorrent), or the unique ID we can hash (as with the printers), and then using that hash together with the network topology to route messages to store information, request it, etc. This technique is called a Distributed Hash Table or just DHT. Freenet, BitTorrent, and IPFS are special purpose DHTs, but there are some general purpose DHTs-as-tools, such as Chord, Pastry, and Kademlia, which are not really "for" anything in particular, so much as a DHT design that you can use to build applications like Freenet or BitTorrent. In a DHT, the thing being hashed, or sometime the hash itself, is called the "key" that the data or metadata is being stored at.

But DHTs as described are only really good for one specific kind of query for data: you have to know the specific thing you want, and have its hash (or some metadata hash) in hand, and when you request it, you get precisely what that hash refers to and nothing else. Many problems do not actually work that way. For instance, in the case of a compute resource or a print resource, we might not want to find a *specific* thing, but rather one that has meets some minimum requirements. Maybe we need a printer that can print in color, or maybe we need a printer that can print A4, or maybe we need a CPU with a speed of at least 1GHz. Some of these can be hacked into a DHT. For instance, color or print size can be treated as the "key" to be hashed, and then at that hash is stored a list of printer IDs that can print color, or print a specific size. That means to find out what printer can print color means just hashing the string "color" and looking it up in the DHT. Compound queries like "color and A4" can reduce to two lookups on "color" and "A4" and then just intersecting the returned lists of printer IDs. Many things can be viewed through this lens, where each "attribute" is turned into a key, and then the list of things with the attribute is stored in the DHT at the peers nearest the hashed key. But that really isn't ideal in many cases where the attributes are few in number and widely used, thus placing heavy burden on a small number of peers who are close to those specific keys. If the only two color settings a printer can have are "black_and_white" and "color", then two-ish peers will be responsible for all the color information about *all* of the printers! It'd be better to somehow distribute that information around the network instead.

Worse still, some problems just really *aren't* suited for DHTs except very indirectly. How do we store CPU information, for instance? Do we use the CPU speed in MHz as the key? Then we'd be storing computers with 1GHz CPUs under the hash of "1000", and computers with 1.1GHz under the hash of "1100" and so on. Ok, but then how do we look up all the computers with at least 1GHz? we'd have to make many queries, for the keys "1000" and "1100" and "1200" and "1300" and ... well, at some point it's too much. You have to many possible speed values, and you'll want to start binning them into ranges so that 1GHz and 1.001GHz are "equivalent" insofar as their hash. Maybe then you don't store and query by specific speeds, but rather by speed ranges, hashing "1000-2000", say, and using that as the key to store all the CPU information for speeds 1GHz to 2GHz. But even this is often inadequate. If you have a single parameter like this, it's not too bad, but what if you have 2? or 10? or 100? Or what if there's so much data that there's no way to form buckets that are both usefully small but also usefully few in number so as to make minimize network requests.

This has lead researchers to invent all sorts of interesting ways to structure p2p networks to better suit this kind of data, and the associated queries that aim to retrieve whole ranges of possible values, not just particular values. Sometimes this involves structuring the keys. For instance, one option would be to store a search tree in a DHT, where the key is the range that the tree node covers, and the data stored at that key is perhaps a list of inhabited sub-ranges of some fixed size determined by the fanout of the tree. Or maybe DHTs are entirely abandoned and instead some other structure is used. This is often the case when search efficiency becomes important, because the DHT itself piggybacks on the routing topology. A different data structure, for instance a search tree, could also have a different routing topology that's faster than the equivalent tree embedded into a DHT.

But this all presupposes some kind of higher dimensional space of possible values that are queried, which is to say something that looks kind of like contiguous chunks of `|R^n`. Many problem domains are simply not parametric like this at all. For instance, an index of documents that lets the user search via fuzzy matching of strings miiiiight be able to be squeezed into a DHT, but as soon as that becomes matching via regular expressions, the problem is entirely impossible to transform into a DHT at all in any remotely obvious way. And yet sometimes that's precisely the kind of query you want to do. So whole other kinds of architectures are required for that. It *is* possible to have a network that supports such queries, for instance by flooding a query message to every peer in the network, but when possible, the topology of the network often is designed to match the kind of data that's going to be stored and the kind of queries that are going to be run.

## Wrap Up

That about covers it for the big picture of peer-to-peer technology. This isn't intended to be a complete or in depth overview, just a good-enough overview that anyone not familiar with p2p can get their feet wet and won't be lost when looking at specific p2p tools or designs. The rest of this reference will look at further p2p issues in depth. That's going to include high level issues such as identity, spam, how decentralized systems become centralized, etc. as well as mid to low level issues like multi-dimensional queries and particular p2p designs.